# -*- coding: utf-8 -*-
"""урок 10 2"Bag of words.ipynb"

Automatically generated by Colaboratory.


# Упражнение на получение мешка слов## Инструкция по выполнению задания
Ниже находится несколько  упражнений, представляющих собой код с пропущенными фрагментами, которые надо воспроизвести. Часть из этих упражнений очень простые, над некоторыми надо хорошенько подумать.

Чтобы выполнить это задание, нужно сохранить копию файла себе на Google Диск.
После выполнения задания, его нужно отправить на проверку. Для этого достаточно предоставить доступ к файлу и отправить ссылку в соответствующее поле LMS курса.
Удачи в выполнении заданий!
# Импорт библиотек
"""

!pip install pymorphy2

import nltk
nltk.download('punkt') # для токенизации необходимо скачать модуль
import pymorphy2 # библиотека для лемматизации
nltk.download('stopwords')
import sys

# для мешка слов и TF-IDF импортируем:
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
import nltk
nltk.download('punkt') # для токенизации необходимо скачать модуль
import pymorphy2 # библиотека для лемматизации

"""## Тексты для обработки
На русском и английском.
"""

eng = '''The 20th century was very notable with its unparalleled technological advancement of humanity.
 With each passing day the lasting impact that we leave on our planet becomes more and more apparent.
  The most obvious and harmful outcomes of heavy industrialization are global warming and climate change.'''
rus = '''XX столетие было очень примечательным из-за беспрецедентного технологического скачка человечества. 
С каждым днём долгие последствия нашего влияния на планету становятся всё более и более заметными. 
Наиболее очевидные и пагубные результаты тотальной индустриализации – глобальное потепление и изменение климата.'''

"""### Упражнение 1
Прежде чем преобразовать данные в мешок слов, проведите предварительную обработку текстов. Для этого повторите последовательность действий из предыдущего задания: токенизируйте тексты, преобразуйте к нижнему регистру, удалите стоп-слова, лемматиризуйте.
"""

eng_words = nltk.word_tokenize(eng, language='english')
eng_words = list(eng_words)

rus_words = nltk.word_tokenize(rus, language='russian')
rus_words = list(rus_words)



fillterEngWords = eng_words[:]


for eng_word in fillterEngWords:
  if eng_word in nltk.corpus.stopwords.words('english'):
    fillterEngWords.remove(eng_word)
    
print(fillterEngWords)
print(len(eng_word))
print(len(fillterEngWords))


fillterRusWords = rus_words[:]

for rus_word in fillterRusWords:
  if rus_word in nltk.word_tokenize(rus_word, language='russian'):
    fillterRusWords.remove(rus_word)

print(fillterRusWords)
print(len(rus_word))
print(len(fillterRusWords))

punct = ['-', '.', ',', ':', ';', '«', '»', ')', '(', '’', '“', '”']
cleanEngWords = fillterEngWords[:]

for clword in fillterEngWords:
  if clword in punct:
    cleanEngWords.remove(clword)
print(cleanEngWords)
print(len(fillterEngWords))
print(len(cleanEngWords))




cleanRusWords = fillterRusWords[:]
for rus_word in fillterRusWords:
  if rus_word in punct:
    cleanRusWords.remove(rus_word)
print(cleanRusWords)
print(len(fillterRusWords))


lowerEngWords = []
for word in cleanEngWords:
  lowerEngWords.append(word.lower())
print(lowerEngWords)
lowerRusWords = []
for word in cleanRusWords:
  lowerRusWords.append(word.lower())
print(lowerRusWords)



"""### Упражнение 2
Создайте объект класса CountVectorizer и с помощью метода fit_transform() получите мешок слов. Полученный мешок слов выведите на экран в виде массива (преобразовав его методом toarray()). Помните, что для получения мешка слов на вход CountVectorizer нужно подать текст, разбитый на предложения. При этом слова должны быть приведены к исходной форме. 
"""

from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer()

bagEng = vectorizer.fit_transform(lowerEngWords)

bagRus = vectorizer.fit_transform(lowerRusWords)
print(vectorizer.get_feature_names()) # массив в виде чисел

print(vectorizer.vocabulary_)

print(bagEng.toarray())
print(bagRus.toarray())

"""### Упражнение 3
Создайте объект класса TfidfVectorizer и с помощью метода fit_transform() получите TF-IDF характеристику. Полученную характеристику выведите на экран в виде массива (преобразовав ее методом toarray()).
"""

from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer()

tfidEng = tfidf.fit_transform(lowerEngWords)
tfidRus = tfidf.fit_transform(lowerRusWords)

print(tfidf.get_feature_names())

print(tfidf.vocabulary_)

print(tfidEng.toarray())

print(tfidRus.toarray())